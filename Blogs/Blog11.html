<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Blog11</title>
    <link rel="stylesheet" href="../Style.css" />
    <link rel="stylesheet" href="../normalize.css" />
    <link rel="stylesheet" href="Blogs.css" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css"
    />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Kanit:wght@400;700&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Unna:wght@400;700&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@400;700&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&display=swap"
      rel="stylesheet"
    />
    <script src="../Scripts/ActivePage.js"></script>
    <script src="../Scripts/Script.js"></script>
    <script src="../Scripts/Blogs.js"></script>
  </head>
  <body>
    <header class="page header">
      <nav class="menu" aria-label="Main Navigation">
        <i class="fas fa-bars" id="burgerbutton"></i>
        <i class="fas fa-times" id="closeButton"></i>
        <img src="../Images/Logo.png" alt="Logo" class="Logo" />
        <ul>
          <li><a href="../index.html" class="u-url">Home</a></li>
          <li><a href="MainBlogPage.html" class="u-url active">Blogs</a></li>
          <li>
            <a href="../Portfolio/portfolio.html" class="u-url">Portfolio</a>
          </li>
          <li>
            <a href="../Design/MainDesignPage.html" class="u-url">Design</a>
          </li>
          <li><a href="../Essays/EssaysPage.html" class="u-url">Essays</a></li>
          <li class="ContactButtonContainer">
            <button
              class="ContactButton"
              onclick="location.href='../index.html#Contact'"
            >
              Contact
            </button>
          </li>
        </ul>
      </nav>
    </header>
    <main>
      <h1 class="normalheading">Blog 11: Digital Inequalities and AI</h1>
      <time datetime="2025-05-05" class="dt-published"
        ><span class="timeBlog">5 May 2025, 23:00</span></time
      >
      <div class="nav-buttons">
        <div class="ButtonBackground">
          <i
            id="Previous"
            class="fas fa-angle-left"
            onclick="location.href='Blog10.html'"
          ></i>
        </div>
        <div class="ButtonBackground">
          <i
            id="Next"
            class="fas fa-angle-right"
            onclick="location.href='Blog12.html'"
          ></i>
        </div>
      </div>
      <section>
        <h3>
          Lutz(2019) - "Digital inequalities in the Age of Artificial
          intelligence"
        </h3>
        <article>
          <p>
            Christian Lutz’s article speaks on an interesting upcoming issue of
            how artificial intelligence (AI) systems risk amplifying existing
            social and digital inequalities. Through a close reading of the
            text, I was struck by how the author dissects both the technical and
            social frameworks of AI implementation, especially in public
            services and employment sectors. After one brief reading of the
            text, I struggled to relay and understand his intention and meaning
            but after a brief second and third reading is when everything shone
            through for me, his purpose along with my interpretation is to break
            down digital inequality and the underlying bias that serves it.
          </p>
          <p>
            Christian Lutz opens his argument by challenging the common
            perception that artificial intelligence (AI) systems are inherently
            objective or neutral. He asserts that this assumption is deeply
            flawed and potentially dangerous because it ignores the
            socio-technical realities of how AI systems are created and
            deployed. Instead of being impartial tools, AI systems reflect the
            biases both of the individuals and institutions that design them, as
            well as the data sets they are trained on. The data is formed by
            historical data entries created by humans which will inherently have
            biased and objective information and opinions, which in some cases
            could be seen as mis-information.
          </p>
          <p>
            When AI is used in areas like policing, hiring, or welfare, it can
            unfairly disadvantage demographic groups by instilling
            discriminatory patterns in them. This creates social barriers and
            biases that become embedded in our society as norms, these biases
            become harder to detect because algorithms appear “neutral” or fair
            ,but in actual fact they are masking their impact just because it
            was created by technology. Lutz argues that designing,creating and
            publishing AI systems is a deeply social political and ethical
            process, requiring transparency and honesty to try close the
            disparity and at the same time allowing input from these
            demographics to avoid deepening social inequalities. All in all He
            simply means the outcome of the ai system is rooted in choices of
            information influenced by pre-determined constructs.
          </p>
          <p>
            Later in his article, Lutz explains that one of the big problems
            with artificial intelligence (AI) is that it creates a huge gap
            between those who understand and control it, and those who are
            affected by it who may not have access to it. Most regular people
            don’t know how these systems work, while big tech companies and
            governments have the knowledge, tools, and data to build and use
            them. This creates what he calls “informational symmetry”, which
            means that one side has much more information and power than the
            others hence creating the huge disparity in digital inequality
            mentioned over and over in the passage
          </p>
          <p>
            Because AI systems are often complicated and not very transparent,
            people usually don’t get to see how decisions are made. For example,
            if someone is rejected from a job, denied government help, or is
            rated as “high risk” by an algorithm, they might never be told why
            or how that decision was made. This makes it very hard for people to
            speak up, ask questions, or fix unfair treatment.
          </p>
          <p>
            Lutz says this is dangerous because it weakens democracy. In a
            healthy democracy, people should be able to understand and challenge
            decisions that affect their lives. But with AI, more and more
            important decisions are being made by systems that are hidden from
            view and controlled by a few powerful organizations. This can lead
            to a loss of trust in public systems and can make people feel
            powerless.
          </p>
          <p>
            To sum up, Christian Lutz’s article helped me understand that AI is
            not just a smart tool,it can also be unfair if we’re not careful. It
            often reflects human bias and can increase unfairness in society,
            especially when people don’t know how it works or can’t challenge
            its decisions. Lutz shows that AI systems are shaped by people and
            their choices, so we need to make sure these systems are clear,
            fair, and involve everyone and not just powerful companies or
            governments. His message is clear, make AI fair for all, we need
            more openness, more equality, and more public involvement.
          </p>

          <h4>References:</h4>
          <p>
            Lutz, C., 2019. Digital inequalities in the age of artificial
            intelligence and big data. Human Behavior and Emerging Technologies,
            1(2), pp.141-148.
          </p>
        </article>
      </section>
    </main>
    <button id="backToTopBtn" aria-label="Back to top">
      <i class="fas fa-arrow-up"></i>
    </button>
    <footer>
      <div id="wrapper">
        <ul>
          <li class="numb"><span>1</span></li>
          <li class="numb"><span>2</span></li>
          <li class="numb"><span>3</span></li>
          <li class="numb"><span>4</span></li>

          <li class="numb"><span>7</span></li>

          <li class="numb"><span>9</span></li>
          <li class="numb"><span>10</span></li>
          <li class="numb"><span>11</span></li>
          <li class="numb"><span>12</span></li>
          <li class="numb"><span>13</span></li>
        </ul>
      </div>
    </footer>
  </body>
</html>
